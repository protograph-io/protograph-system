{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import psycopg2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Establish a connection with the database"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\n",
    "  'database': 'postgres',\n",
    "  'user': 'postgres',\n",
    "#   'password': '',                                        ####### removed for security purposes\n",
    "  'host': 'db.ozfxxdvqaykhwqfijquv.supabase.co',\n",
    "  'port': 5432\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**params)\n",
    "cursor = conn.cursor()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print all the tables\n",
    "cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "       WHERE table_schema = 'public'\"\"\")\n",
    "\n",
    "for table in cursor.fetchall():\n",
    "    print(table)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dump all the tables to a local folder\n",
    "# This takes a minute depending on internet quality. Consider just asking Judge 1 for the zipped folder instead.\n",
    "cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "       WHERE table_schema = 'public'\"\"\")\n",
    "\n",
    "for table in np.array(cursor.fetchall())[::-1]:\n",
    "    print(table)\n",
    "    if table[0] != 'prototypes':\n",
    "        df = pd.read_sql_query(f'select * from \"{table[0]}\"',con=conn)\n",
    "        df.to_csv(f'csv_dump/{table[0]}.csv')"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load survey questions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "entries = pd.read_csv('csv_dump/study_entries.csv')\n",
    "entries = entries[entries['updated_at'].notna()].copy() # get rid of entries where nothing happened\n",
    "survey = pd.read_csv('csv_dump/study_survey_questions.csv')"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# merge prolific_id into survey\n",
    "survey['prolific_id'] = \"\"\n",
    "for study_id in survey['study_id']:\n",
    "    survey.loc[survey['study_id']==study_id, 'prolific_id'] = entries[entries['id']==study_id]['prolific_pid'].item()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the study results (graded performance from users)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df1 = pd.read_csv('csv_dump/user_study_scores-Grader1.csv')\n",
    "df1['grader'] = 'Grader1'\n",
    "\n",
    "df2 = pd.read_csv('csv_dump/user_study_scores-Grader2.csv')\n",
    "df2['grader'] = 'Grader2'\n",
    "\n",
    "# some sanity checks\n",
    "assert all([id1 == id2 for (id1, id2) in zip(df1['study_id'].values, df2['study_id'].values)])\n",
    "assert all([col1 == col2 for (col1, col2) in zip(df1.columns, df2.columns)])\n",
    "\n",
    "df1 = df1.drop(columns=['p3t1:complexity', 'p3t1:new commands', 'p3t1:line count'])\n",
    "df2 = df2.drop(columns=['p3t1:complexity', 'p3t1:new commands', 'p3t1:line count'])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.concat([df1, df2])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert step count to 0 or 1\n",
    "df['p1t3:steps'] = df['p1t3:steps']==3\n",
    "df['p1t3:steps'] = df['p1t3:steps'].astype(int)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# melt the dataframe (convert to longform)\n",
    "\n",
    "# helper mappings\n",
    "def section_name_map(x):\n",
    "    mapping = {\n",
    "        'p1' : 'Writing',\n",
    "        'p2' : 'Reading'\n",
    "    }\n",
    "    return mapping[x]\n",
    "\n",
    "def task_name_map(x):\n",
    "    mapping = {\n",
    "        'p1t1' : 'Writing task 1',\n",
    "        'p1t2' : 'Writing task 2',\n",
    "        'p1t3' : 'Writing task 3',\n",
    "        'p2t1' : 'Reading task 1',\n",
    "        'p2t2' : 'Reading task 2',\n",
    "        'p2t3' : 'Reading task 3',\n",
    "    }\n",
    "    return mapping[x]\n",
    "\n",
    "id_vars = ['study_id', 'grader']\n",
    "value_vars = set(df1.columns).difference(set(id_vars))\n",
    "dfl = pd.melt(df, id_vars=id_vars, value_vars=value_vars)\n",
    "dfl['task_id'] = dfl['variable'].apply(lambda x : x.split(':')[0])\n",
    "dfl['property'] = dfl['variable'].apply(lambda x : x.split(':')[-1])\n",
    "dfl['section'] = dfl['task_id'].apply(lambda x : x[:2])\n",
    "dfl['task name'] = dfl['task_id'].apply(task_name_map)\n",
    "dfl['section name'] = dfl['section'].apply(section_name_map)\n",
    "dfl = dfl[dfl['section']!='p3'].copy()\n",
    "\n",
    "dfl.head()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# peak at differences between Grader2 and Grader1 scores\n",
    "diff_df = dfl[dfl['grader']=='Grader1'].copy()\n",
    "p_df = dfl[dfl['grader']=='Grader2'].copy()\n",
    "diff_df['different'] = ~(diff_df['value'].values == p_df['value'].values)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "sns.barplot(x='variable', y='different', ci=None, ax=ax, data=diff_df)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "disagreements = diff_df['different'].sum()\n",
    "total_agreement = 1 - (disagreements / len(diff_df))\n",
    "print(f'disagreements between Grader1 and Grader2:{disagreements}.')\n",
    "print(f'disagreements between Grader1 and Grader2:{total_agreement}.')\n",
    "None"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let's just average Grader2 and Grader1 scores for now\n",
    "dfl = dfl.groupby(['study_id', 'variable', 'task name', 'property', 'section name']).mean().reset_index()"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# merge with some survey questions..\n",
    "dfl['education'] = -1\n",
    "dfl['familiarity'] = -1\n",
    "dfl['experience'] = -1\n",
    "dfl['duration'] = -1\n",
    "dfl['db_id'] = \"\"\n",
    "\n",
    "for study_id in dfl['study_id'].unique():\n",
    "    dfl.loc[dfl['study_id']==study_id, 'education'] = survey[survey['prolific_id'] == study_id]['education'].item()\n",
    "    dfl.loc[dfl['study_id']==study_id, 'familiarity'] = survey[survey['prolific_id'] == study_id]['familiarity'].item()\n",
    "    dfl.loc[dfl['study_id']==study_id, 'experience'] = survey[survey['prolific_id'] == study_id]['experience'].item()\n",
    "    dfl.loc[dfl['study_id']==study_id, 'duration'] = entries[entries['prolific_pid'] == study_id]['duration'].max()/60\n",
    "    dfl.loc[dfl['study_id']==study_id, 'db_id'] = entries[entries['prolific_pid'] == study_id]['id'].item()\n",
    "    \n",
    "assert -1 not in dfl['education'].values\n",
    "assert -1 not in dfl['familiarity'].values\n",
    "assert -1 not in dfl['experience'].values\n",
    "assert -1 not in dfl['duration'].values\n",
    "assert \"\" not in dfl['db_id'].values"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfl.to_csv('csv_dump/processed_study_results.csv')"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skip_layers",
   "language": "python",
   "name": "skip_layers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}